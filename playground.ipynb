{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of Samples: 100\n",
      "Number of Samples: 100\n",
      "Sample: Data(x=[2483, 3], y=[2483], pos=[2483, 3], category=[1])\n",
      "Sample: Data(x=[2483, 3], y=[2483], pos=[2483, 3], category=[1])\n",
      "Number of points: 2483, Dimension of each point: 3\n",
      "Number of points: 2483, Dimension of each point: 3\n",
      "Number of points: 2635, Dimension of each point: 3\n",
      "Number of points: 2635, Dimension of each point: 3\n",
      "Number of Training Samples: 80\n",
      "Number of Training Samples: 80\n",
      "Number of Test Samples: 20\n",
      "Number of Test Samples: 20\n",
      "Train dataset[0]: Data(x=[2048, 3], y=[2048], pos=[2048, 3], category=[1])\n",
      "Train dataset[0]: Data(x=[2048, 3], y=[2048], pos=[2048, 3], category=[1])\n",
      "Test dataset[0]: Data(x=[2048, 3], y=[2048], pos=[2048, 3], category=[1])\n",
      "Test dataset[0]: Data(x=[2048, 3], y=[2048], pos=[2048, 3], category=[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point cloud saved to ./plots/point_cloud_9.ply\n",
      "Train Batch:  DataBatch(x=[32768, 3], y=[32768], pos=[32768, 3], category=[16], batch=[32768], ptr=[17])\n",
      "Test Batch:  DataBatch(x=[32768, 3], y=[32768], pos=[32768, 3], category=[16], batch=[32768], ptr=[17])\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "from torch_geometric.loader import DataLoader  # Correct import\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", filename=\"sharpnet.log\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "from utils import plot_3d_shape, save_point_cloud_ply, ResamplePoints, save_model, chamfer_loss, mmd_cd_loss, chamfer_loss_eval\n",
    "from models import ResnetGenerator, NLayerDiscriminator\n",
    "\n",
    "# Path to the dataset\n",
    "DATASET_PATH = \"./shapenetcore_partanno_segmentation_benchmark_v0_normal\"\n",
    "SPLIT_RATIO = 0.8\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1 #50\n",
    "\n",
    "# Optimizers\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "LEARNING_RATE = 0.0002\n",
    "\n",
    "# Initialize networks\n",
    "INPUT_NC = 3\n",
    "OUTPUT_NC = 3\n",
    "NGF = 64\n",
    "NDF = 64\n",
    "NUM_BLOCKS = 6\n",
    "\n",
    "# Training parameters\n",
    "ACCUMULATION_STEPS = 1\n",
    "batch_size = 1  # Start with a very small batch size\n",
    "TARGET_SIZE = 64  # Reduced target size for smaller GPU usage\n",
    "\n",
    "MODEL_PATH = \"./saved_models\"\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "PLOT_PATH = \"./plots\"\n",
    "os.makedirs(PLOT_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset = ShapeNet(root=DATASET_PATH, categories=[\"Airplane\"]).shuffle()[:100]\n",
    "# Provide the correct path to the extracted dataset\n",
    "# dataset = ShapeNet(root=dataset_path, categories=[\"Table\", \"Lamp\", \"Guitar\", \"Motorbike\"]).shuffle()[:1000]\n",
    "\n",
    "logger.info(f\"Number of Samples: {len(dataset)}\")\n",
    "logger.info(f\"Sample: {dataset[0]}\")\n",
    "\n",
    "sample = dataset[0]\n",
    "logger.info(f\"Number of points: {sample.pos.shape[0]}, Dimension of each point: {sample.pos.shape[1]}\")\n",
    "\n",
    "#%%\n",
    "# Visualize a sample\n",
    "sample_idx = 9\n",
    "# plot_3d_shape(dataset[sample_idx]) # NOTE: each data points have different shapes\n",
    "save_point_cloud_ply(dataset[sample_idx], os.path.join(PLOT_PATH, f\"point_cloud_{sample_idx}.ply\"))\n",
    "logger.info(f\"Number of points: {dataset[sample_idx].pos.shape[0]}, Dimension of each point: {dataset[sample_idx].pos.shape[1]}\")\n",
    "#%% \n",
    "# Data Augmentation\n",
    "augmentation = T.Compose([\n",
    "    ResamplePoints(2048),\n",
    "    T.RandomJitter(0.03),\n",
    "    T.RandomFlip(axis=1),\n",
    "    T.RandomShear(0.2)\n",
    "])\n",
    "\n",
    "# Apply augmentation\n",
    "dataset.transform = augmentation\n",
    "\n",
    "#%%\n",
    "# DataLoader\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "train_size = int(SPLIT_RATIO * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Verify the batch sizes\n",
    "for batch in train_loader:\n",
    "    print(\"Train Batch: \", batch)\n",
    "    break\n",
    "\n",
    "for batch in test_loader:\n",
    "    print(\"Test Batch: \", batch)\n",
    "    break\n",
    "\n",
    "logger.info(f\"Number of Training Samples: {len(train_dataset)}\")\n",
    "logger.info(f\"Number of Test Samples: {len(test_dataset)}\")\n",
    "logger.info(f\"Train dataset[0]: {train_dataset[0]}\")\n",
    "logger.info(f\"Test dataset[0]: {test_dataset[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch:  DataBatch(x=[32768, 3], y=[32768], pos=[32768, 3], category=[16], batch=[32768], ptr=[17])\n",
      "Train Batch pos shape:  torch.Size([32768, 3])\n",
      "Train Batch y shape:  torch.Size([32768])\n",
      "torch.Size([16, 3, 1, 2048])\n"
     ]
    }
   ],
   "source": [
    "for train_batch in train_loader:\n",
    "    print(\"Train Batch: \", train_batch)\n",
    "    print(\"Train Batch pos shape: \", train_batch.pos.shape)\n",
    "    print(\"Train Batch y shape: \", train_batch.batch.shape)\n",
    "    print(train_batch.pos.view(BATCH_SIZE, 3, 2048).contiguous().unsqueeze(3).permute(0, 1, 3, 2).shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvig_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
